{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit,ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import ndcg_score, classification_report, f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '2021-07-19'\n",
    "\n",
    "# method = 'scibert'\n",
    "# # method = 'tfidf'\n",
    "# # method = 'glove'\n",
    "\n",
    "# # time_window = 1\n",
    "# time_window = 6\n",
    "\n",
    "# contain_zero = False\n",
    "# # contain_zero = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(model):\n",
    "    if model == 'SVM':\n",
    "        param_grid = {'kernel':['linear', 'poly', 'rbf', 'sigmoid',],\n",
    "                      'tol':[1e-1, 1e-2,1e-3, 1e-4, 1e-5],\n",
    "                      'C': [0.1, 1, 10, 100],  \n",
    "                      'gamma': [1, 0.1, 0.01, 0.001, 0.0001,'scale', 'auto']}\n",
    "        return SVC, param_grid\n",
    "    if model == 'Logistic':\n",
    "        param_grid = [{'penalty':['l1', 'l2'],\n",
    "                      'solver':['liblinear', 'saga'],\n",
    "                      'tol':[1e-1, 1e-2,1e-3, 1e-4, 1e-5],\n",
    "                      'C': [0.1, 1, 10, 100]},]\n",
    "        return LogisticRegression, param_grid\n",
    "    if model == 'DecisionTree':\n",
    "        param_grid={\n",
    "            'criterion':['gini','entropy'],\n",
    "            'splitter':['best','random'],\n",
    "            'max_depth':[2,3,4,5,6,7,8,9,10],\n",
    "            'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "            \n",
    "        }\n",
    "        return DecisionTreeClassifier,param_grid\n",
    "    if model == 'RandomForest':\n",
    "        param_grid={\n",
    "            'n_estimators':[50,100,150,200,250,300],\n",
    "            'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "            'criterion':['gini','entropy'],\n",
    "            'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "        }\n",
    "        return RandomForestClassifier,param_grid\n",
    "    if model == 'GaussianNB':\n",
    "        param_grid={\n",
    "            'var_smoothing':[1e-9,1e-8,1e-7,1e-6,1e-5],\n",
    "        }\n",
    "        return GaussianNB,param_grid\n",
    "    if model == 'MLP':\n",
    "        param_grid={\n",
    "            'hidden_layer_sizes':[4,8,16,32,64],\n",
    "            'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "            'alpha':[1e-5,1e-4,1e-3,1e-2],\n",
    "            'learning_rate_init':[1e-3,1e-2,1e-1],\n",
    "            'early_stopping':[True],\n",
    "            \n",
    "        }\n",
    "        return MLPClassifier,param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(data_dir,method,time_window,contain_zero,class_threshold,model_name,fw,subsampling = False):\n",
    "    valid_samples = pd.read_csv(f'指标初步探索/valid_samples_{data_dir}_{method}_timewindow_{time_window}.csv',sep='\\t')\n",
    "#     print(valid_samples.shape)\n",
    "    if not contain_zero:\n",
    "        valid_samples = valid_samples.loc[valid_samples['count']>0]\n",
    "#     print(valid_samples.shape)\n",
    "    all_year_month = ['2020-01','2020-02','2020-03','2020-04','2020-05','2020-06','2020-07','2020-08','2020-09','2020-10',\n",
    "                     '2020-11','2020-12','2021-01','2021-02','2021-03']\n",
    "    year_months_train = all_year_month[1:-time_window-1]\n",
    "    year_months_test = all_year_month[-time_window-1:-time_window]\n",
    "    \n",
    "    \n",
    "    valid_samples_train = valid_samples.loc[valid_samples['publish_year_month'].isin(year_months_train)]\n",
    "    \n",
    "#     print(valid_samples_train.shape)\n",
    "    \n",
    "    valid_samples_test = valid_samples.loc[valid_samples['publish_year_month'].isin(year_months_test)]\n",
    "    valid_samples_train['clf_label'] = (valid_samples_train['count']>class_threshold).astype(int)\n",
    "#     print(valid_samples_train.shape)\n",
    "    exp_setting = {\n",
    "        'method':method,\n",
    "        'time_window':time_window,\n",
    "        'contain_zero':contain_zero,\n",
    "        'class_threshold':class_threshold,\n",
    "        'model_name':model_name\n",
    "    }\n",
    "    \n",
    "    if len(set(valid_samples_train['clf_label']))==1:\n",
    "#         exp_setting = {\n",
    "#             'method':method,\n",
    "#             'time_window':time_window,\n",
    "#             'contain_zero':contain_zero,\n",
    "#             'class_threshold':class_threshold,\n",
    "#             'model_name':model_name\n",
    "#         }\n",
    "        exp_setting['results'] = None\n",
    "        return exp_setting\n",
    "    \n",
    "    if subsampling is True:\n",
    "        majority_data = valid_samples_train[valid_samples_train['clf_label'] == 0]\n",
    "        minority_data = valid_samples_train[valid_samples_train['clf_label'] == 1]\n",
    "        majority_data = majority_data.sample(n=minority_data.shape[0],replace=False,random_state=0,axis=0)\n",
    "        valid_samples_train = pd.concat([majority_data, minority_data],axis=0).sample(frac=1.,replace=False,random_state=0,axis=0)\n",
    "    \n",
    "    valid_samples_test['clf_label'] = (valid_samples_test['count']>class_threshold).astype(int)\n",
    "    X_train, X_test = valid_samples_train[['min_cos_distance','min_cos_distance']].values, valid_samples_test[['min_cos_distance','min_cos_distance']].values\n",
    "    Y_train, Y_test = valid_samples_train[['clf_label']].values.flatten(), valid_samples_test[['clf_label']].values.flatten()\n",
    "    \n",
    "    \n",
    "    train_num, test_num = X_train.shape, X_test.shape\n",
    "#     print(train_num, test_num)\n",
    "    \n",
    "    model, params_grid = classifier(model_name)\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    for params in tqdm(ParameterGrid(params_grid)):\n",
    "        if model_name == 'GaussianNB':\n",
    "            clf = model(**params)\n",
    "        else:\n",
    "            clf = model(**params,random_state=0)\n",
    "#         print(Y_train)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        score = f1_score(Y_test, clf.predict(X_test))\n",
    "        if score>=best_score:\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "#         print(best_params)\n",
    "    \n",
    "#     fw.write(f\"time_window-{time_window},contain_zero-{contain_zero},class_threshold-{class_threshold},model_name-{model_name}\")\n",
    "#     fw.write('\\n')\n",
    "#     print(best_params)\n",
    "#     exit()\n",
    "#     fw.write(json.dumps(best_params))\n",
    "#     fw.write('\\n')\n",
    "    if model_name == 'GaussianNB':\n",
    "        exp_setting['results'] = classification_report(Y_test,model(**best_params).fit(X_train, Y_train).predict(X_test),digits=4)\n",
    "    else:\n",
    "        exp_setting['results'] = classification_report(Y_test,model(**best_params,random_state=0).fit(X_train, Y_train).predict(X_test),digits=4,output_dict=True)\n",
    "    return exp_setting\n",
    "#     fw.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:22<00:00,  4.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:52<00:00,  2.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:25<00:00,  4.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:22<00:00,  4.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:21<00:00,  5.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:53<00:00,  2.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:34<00:00,  3.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:28<00:00,  3.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [02:34<00:00,  1.43s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:55<00:00,  1.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:38<00:00,  2.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:30<00:00,  3.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:20<00:00,  5.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:40<00:00,  2.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:23<00:00,  4.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:21<00:00,  5.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:20<00:00,  5.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:44<00:00,  2.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:30<00:00,  3.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:25<00:00,  4.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [01:48<00:00,  1.00s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:43<00:00,  2.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:31<00:00,  3.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:28<00:00,  3.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:20<00:00,  5.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:18<00:00,  5.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:46<00:00,  2.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:25<00:00,  4.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:21<00:00,  4.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:20<00:00,  5.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:47<00:00,  2.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:32<00:00,  3.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:26<00:00,  4.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [02:24<00:00,  1.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:52<00:00,  2.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:34<00:00,  3.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:30<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "global_index = 0\n",
    "for model_name in ['RandomForest']:# 'GaussianNB','Logistic','MLP','DecisionTree','SVM'\n",
    "#     fw = open(f'{model_name}_{data_dir}_{method}.log','w',encoding='utf-8')\n",
    "    for data_dir in ['2021-07-19']:\n",
    "        for method in ['scibert','tfidf','glove']:\n",
    "            for time_window in [1,6]:\n",
    "                for contain_zero in [False,True]:\n",
    "                    for class_threshold in [0,1,2,3]:\n",
    "                        tmp = train_(data_dir,method,time_window,contain_zero,class_threshold,model_name,fw=None, subsampling=True)\n",
    "                        results[global_index] = tmp\n",
    "                        global_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[['accuracy', 'macro_avg', 'precision', 'recall', 'f1']] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx, row_content in results_df.iterrows():\n",
    "    results = row_content['results']\n",
    "    \n",
    "    if results is None:\n",
    "        accuracy, macro_avg, precision, recall, f1 = -1,-1,-1,-1,-1\n",
    "    else:\n",
    "        accuracy, macro_avg, precision, recall, f1 = \\\n",
    "            results['accuracy'], results['macro avg']['f1-score'], results['1']['precision'], results['1']['recall'], results['1']['f1-score']\n",
    "    \n",
    "    results_df.at[row_idx,'accuracy'] = accuracy\n",
    "    results_df.at[row_idx,'macro_avg'] = macro_avg\n",
    "    results_df.at[row_idx,'precision'] = precision\n",
    "    results_df.at[row_idx,'recall'] = recall\n",
    "    results_df.at[row_idx,'f1'] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'final_results_{data_dir}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************accuracy************************\n",
      "*************************macro_avg************************\n",
      "time_window:6, contain_zero:False, class_threshold:1\n",
      "*************************precision************************\n",
      "time_window:6, contain_zero:False, class_threshold:1\n",
      "time_window:6, contain_zero:False, class_threshold:2\n",
      "time_window:6, contain_zero:False, class_threshold:3\n",
      "time_window:6, contain_zero:True, class_threshold:1\n",
      "*************************recall************************\n",
      "time_window:1, contain_zero:False, class_threshold:2\n",
      "time_window:1, contain_zero:True, class_threshold:0\n",
      "time_window:6, contain_zero:False, class_threshold:1\n",
      "time_window:6, contain_zero:False, class_threshold:2\n",
      "time_window:6, contain_zero:False, class_threshold:3\n",
      "time_window:6, contain_zero:True, class_threshold:0\n",
      "time_window:6, contain_zero:True, class_threshold:1\n",
      "time_window:6, contain_zero:True, class_threshold:3\n",
      "*************************f1************************\n",
      "time_window:6, contain_zero:False, class_threshold:1\n",
      "time_window:6, contain_zero:False, class_threshold:2\n",
      "time_window:6, contain_zero:False, class_threshold:3\n",
      "time_window:6, contain_zero:True, class_threshold:0\n",
      "time_window:6, contain_zero:True, class_threshold:1\n"
     ]
    }
   ],
   "source": [
    "for metric in ['accuracy', 'macro_avg', 'precision', 'recall', 'f1']:\n",
    "    print(f\"*************************{metric}************************\")\n",
    "    for time_window in [1,6]:\n",
    "        for contain_zero in [False,True]:\n",
    "            for class_threshold in [0,1,2,3]:\n",
    "                tmp = results_df.loc[(results_df['time_window']==time_window)\n",
    "                                  &(results_df['contain_zero']==contain_zero)\n",
    "                                  &(results_df['class_threshold']==class_threshold)\n",
    "                              ]\n",
    "                scibert = tmp.loc[(tmp['method']=='scibert')][metric].values[0]\n",
    "                tfidf = tmp.loc[(tmp['method']=='tfidf')][metric].values[0]\n",
    "                glove = tmp.loc[(tmp['method']=='glove')][metric].values[0]\n",
    "    #             print(scibert)\n",
    "                if scibert > tfidf and scibert > glove:\n",
    "                    print(f\"time_window:{time_window}, contain_zero:{contain_zero}, class_threshold:{class_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
